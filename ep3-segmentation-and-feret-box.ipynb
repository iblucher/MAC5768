{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação das imagens EP3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import exposure, img_as_ubyte, img_as_bool, io \n",
    "from skimage.filters import threshold_otsu, try_all_threshold\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_IMAGE_PATH = Path('ground_truth') / 'brush' / 'gt_IMG_1431.JPG'\n",
    "\n",
    "example_img = io.imread(EXAMPLE_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(example_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding \n",
    "\n",
    "ADD DESCRIPTION AND PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_segmentation(img):\n",
    "    thresh = threshold_otsu(img)\n",
    "    binary = img > thresh\n",
    "    \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_GRAY_DATASET_PATH = Path('original_gray_dataset/')\n",
    "SEGMENTED_DATASET_PATH = Path('segmented_dataset')\n",
    "\n",
    "for filename in ORIGINAL_GRAY_DATASET_PATH.rglob('*'):\n",
    "    if filename.is_file():\n",
    "        head, tail = os.path.split(filename)\n",
    "        object_class = head.split('/')[-1]\n",
    "        segmented_path = f'{SEGMENTED_DATASET_PATH}/{object_class}'\n",
    "\n",
    "        os.makedirs(segmented_path, exist_ok=True)\n",
    "        \n",
    "        img = io.imread(filename)\n",
    "        segmented_img = threshold_segmentation(img)\n",
    "        uint8_segmented_img = img_as_ubyte(segmented_img)\n",
    "        io.imsave(f'{segmented_path}/{tail}', uint8_segmented_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cortar imagem na Feret Box\n",
    "\n",
    "ADD DESCRIPTION AND PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_class_dimensions = defaultdict(list)\n",
    "def compute_bounding_box_img(img, object_class, manual_seg=False):\n",
    "    minr, maxr, minc, maxc = compute_bounding_box_dimensions(img)\n",
    "               \n",
    "    if manual_seg:    \n",
    "        object_class_dimensions[object_class].append([minr, maxr, minc, maxc])    \n",
    "        \n",
    "    if not manual_seg and maxr == 1280 and maxc == 720:\n",
    "        minr, maxr, minc, maxc = average_object_dims[object_class]\n",
    "    \n",
    "    box_img = img[minr:maxr, minc:maxc]\n",
    "\n",
    "    return ~box_img\n",
    "\n",
    "\n",
    "def compute_bounding_box_dimensions(img):\n",
    "    img = img < 255  # make image binary (False = white, True = black)\n",
    "    \n",
    "    label_image = label(img)\n",
    "    \n",
    "    area = 0\n",
    "    minr, minc, maxr, maxc = np.zeros(4)\n",
    "    \n",
    "    for region in regionprops(label_image):\n",
    "        if region.area >= 100:\n",
    "            new_minr, new_minc, new_maxr, new_maxc = region.bbox\n",
    "            new_area = (new_maxr - new_minr) * (new_maxc - new_minc)\n",
    "            if new_area > area:\n",
    "                area = new_area\n",
    "                minr, minc, maxr, maxc = new_minr, new_minc, new_maxr, new_maxc\n",
    "                \n",
    "    return minr, maxr, minc, maxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_binary_img(img):\n",
    "    \"\"\"Have the object be black and the background be white.\"\"\"\n",
    "    img = img < 255\n",
    "    \n",
    "    r, c = img.shape\n",
    "    true_sum = img.sum()\n",
    "    \n",
    "    if true_sum / (r * c) > 0.5:\n",
    "        return ~img\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_DATASET_PATH = Path('ground_truth/')\n",
    "GROUND_TRUTH_FERET_BOX_DATASET_PATH = Path('ground_truth_feret_box/')\n",
    "\n",
    "for filename in GROUND_TRUTH_DATASET_PATH.rglob('*'):\n",
    "    if filename.is_file():\n",
    "        head, tail = os.path.split(filename)\n",
    "        object_class = head.split('/')[-1]\n",
    "        \n",
    "        box_path = f'{GROUND_TRUTH_FERET_BOX_DATASET_PATH}/{object_class}'\n",
    "\n",
    "        os.makedirs(box_path, exist_ok=True)\n",
    "        \n",
    "        img = io.imread(filename)\n",
    "        feret_box_img = compute_bounding_box_img(img, object_class, True)\n",
    "        feret_box_flipped = flip_binary_img(feret_box_img)\n",
    "        uint8_feret_box_img = img_as_ubyte(feret_box_flipped)\n",
    "        io.imsave(f'{box_path}/{tail}', uint8_feret_box_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_object_dims = {}\n",
    "\n",
    "for k, v in object_class_dimensions.items():\n",
    "    average_object_dims[k] = [int(np.mean(x)) for x in zip(*v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTED_DATASET_PATH = Path('segmented_dataset')\n",
    "SEGMENTED_FERET_BOX_DATASET_PATH = Path('segmented_feret_box/')\n",
    "\n",
    "for filename in SEGMENTED_DATASET_PATH.rglob('*'):\n",
    "    if filename.is_file():\n",
    "        head, tail = os.path.split(filename)\n",
    "        object_class = head.split('/')[-1]\n",
    "        box_path = f'{SEGMENTED_FERET_BOX_DATASET_PATH}/{object_class}'\n",
    "\n",
    "        os.makedirs(box_path, exist_ok=True)\n",
    "        \n",
    "        img = io.imread(filename)\n",
    "        feret_box_img = compute_bounding_box_img(img, object_class, False)\n",
    "        feret_box_flipped = flip_binary_img(feret_box_img)\n",
    "        uint8_feret_box_img = img_as_ubyte(feret_box_flipped)\n",
    "        io.imsave(f'{box_path}/{tail}', uint8_feret_box_img, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance da segmentação por threshold\n",
    "\n",
    "ADD DESCRIPTION AND PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageStats:\n",
    "    true_positive: int\n",
    "    true_negative: int\n",
    "    false_positive: int\n",
    "    false_negative: int\n",
    "        \n",
    "    def accuracy(self) -> float:\n",
    "        acc = (self.true_positive + self.true_negative) / (self.true_positive + self.true_negative + self.false_positive + self.false_negative)\n",
    "        if np.isnan(acc):\n",
    "            return 0\n",
    "        return acc\n",
    "    \n",
    "    def precision(self) -> float:\n",
    "        precision =  self.true_positive / (self.true_positive + self.false_positive)\n",
    "        if np.isnan(precision):\n",
    "            return 0\n",
    "        return precision\n",
    "    \n",
    "    def recall(self) -> float:\n",
    "        recall = self.true_positive / (self.true_positive + self.false_negative)\n",
    "        if np.isnan(recall):\n",
    "            return 0\n",
    "        return recall\n",
    "\n",
    "\n",
    "    \n",
    "def img_performance_metrics(gt_img, seg_img_resize):\n",
    "    tp, tn, fp, fn = np.zeros(4)\n",
    "    for r in range(seg_img_resize.shape[0]):\n",
    "        for c in range(seg_img_resize.shape[1]):\n",
    "            gt_pixel = gt_img[r, c]\n",
    "            seg_pixel = seg_img_resize[r, c]\n",
    "\n",
    "            if gt_pixel == True and seg_pixel == True:\n",
    "                tp += 1\n",
    "\n",
    "            elif gt_pixel == False and seg_pixel == False:\n",
    "                tn += 1\n",
    "\n",
    "            elif gt_pixel == False and seg_pixel == True:\n",
    "                fp += 1\n",
    "\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "    img_stats = ImageStats(tp, tn, fp, fn)\n",
    "    \n",
    "    return img_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTED_FERET_BOX_DATASET_PATH = Path('segmented_feret_box/')\n",
    "GROUND_TRUTH_FERET_BOX_DATASET_PATH = Path('ground_truth_feret_box/')\n",
    "\n",
    "class_metrics = defaultdict(list)\n",
    "\n",
    "for filename in GROUND_TRUTH_FERET_BOX_DATASET_PATH.rglob('*'):\n",
    "    if filename.is_file():\n",
    "        head, tail = os.path.split(filename)\n",
    "        object_class = head.split('/')[-1]\n",
    "        gt_img = img_as_bool(io.imread(filename))\n",
    "        \n",
    "        segmented_head = head.replace('ground_truth_feret_box', 'segmented_feret_box')\n",
    "        segmented_tail = tail.split('gt_')[-1]\n",
    "        seg_img = io.imread(f'{segmented_head}/{segmented_tail}')\n",
    "        \n",
    "        seg_img_resize = img_as_bool(resize(seg_img, (gt_img.shape[0], gt_img.shape[1]), anti_aliasing=True, order=0))\n",
    "        \n",
    "        metrics = img_performance_metrics(gt_img, seg_img_resize)\n",
    "        \n",
    "        class_metrics[object_class].append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iblucher/.pyenv/versions/3.7.4/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "final_report_metrics = defaultdict(list)\n",
    "\n",
    "for k, v in class_metrics.items():\n",
    "    \n",
    "    mean_acc = np.mean([img_stats.accuracy() for img_stats in v])\n",
    "    mean_precision = np.mean([img_stats.precision() for img_stats in v])\n",
    "    mean_recall = np.mean([img_stats.recall() for img_stats in v])\n",
    "    \n",
    "    final_report_metrics[k] = [mean_acc, mean_precision, mean_recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(final_report_metrics,orient='index')\n",
    "df = df.rename(columns={0: 'Accuracy', 1: 'Precision', 2: 'Recall'}).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>earring</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glasses</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nail_polish</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lipstick</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand_sanitizer</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notebook</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knife</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pen</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mug</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brush</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Accuracy  Precision  Recall\n",
       "earring             0.59       0.34    0.37\n",
       "glasses             0.52       0.35    0.33\n",
       "nail_polish         0.55       0.32    0.49\n",
       "lipstick            0.69       0.42    0.42\n",
       "hand_sanitizer      0.62       0.28    0.41\n",
       "notebook            0.79       0.23    0.51\n",
       "knife               0.59       0.39    0.38\n",
       "pen                 0.59       0.47    0.39\n",
       "mug                 0.65       0.40    0.54\n",
       "brush               0.48       0.36    0.26"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Value\n",
       "Accuracy   0.607\n",
       "Precision  0.356\n",
       "Recall     0.410"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(axis='index').to_frame('Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
